import cv2
import argparse
import os
import shutil
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow
from sklearn.model_selection import train_test_split, StratifiedKFold
from tensorflow.keras import layers
from tensorflow.keras.preprocessing import image

#from PIL import Image

parser = argparse.ArgumentParser(description="Copy mask folders created by SAM")


parser.add_argument("--work_dir",
                    required=True,
                    type=str,
                    default=None,
                    help="Pass the root folder working directory")

parser.add_argument("--masks_sub_dir",
                    required=True,
                    type=str,
                    default=None,
                    help="Pass the folder containing folders of masks for each image")

parser.add_argument("--output_dir",
                    required=True,
                    type=str,
                    default=None,
                    help="destination folder for seelcted images and it's masks")

parser.add_argument("--wbc_list",
                    required=True,
                    type=str,
                    default=None,
                    help="folder containing list of wbc folder names")

parser.add_argument("--final_dimensions",
                    required=True,
                    type=int,
                    default=None,
                    help="enter the desired dimensions for the individual images")

parser.add_argument("--grid_images_dir",
                    required=True,
                    type=str,
                    default=None,
                    help="Pass the root folder working directory")

def copy_wbc_folders_first(args):
    output_dir = os.path.join(args.work_dir,args.output_dir)
    input_dir = os.path.join(args.work_dir,args.masks_sub_dir)
    wbc_list_file = os.path.join(args.work_dir,args.wbc_list)

    if not os.path.exists(input_dir):
        raise("Enter an existing directory")
    
    if not os.path.exists(wbc_list_file):
        raise("Enter the proper path of wbc list csv file")
    else:
        with open(wbc_list_file, "r") as f:
            wbc_list = list(f.read().strip().split(", "))

    os.makedirs(output_dir, exist_ok=True)
    dirs = os.listdir(input_dir)
    for dir in dirs:
        
        if os.path.isdir(os.path.join(input_dir, dir)) and dir in wbc_list:
            op_dir = os.path.join(output_dir, dir)
            os.makedirs(op_dir, exist_ok=True)
            shutil.copytree(os.path.join(input_dir, dir), op_dir, dirs_exist_ok=True)

def csv_labeller(path):
    
    for root, subdirs, files in os.walk(path):
        if files == [] or files == ():
            continue

        csv_file = os.path.join(root, str(root.rsplit("\\", maxsplit = 1)[1]) + ".csv")
        
        df = pd.read_csv(csv_file, header=0)

        if 'label' in df.columns:
            continue
        
        print(csv_file)
        labels = []
        for rows in df['area']:
            if rows > 300:
                labels.append("RBC")
            else:
                labels.append("")
            
        df['label'] = labels
        df.to_csv(csv_file, index= False)

def edit_csv(path):
    
    for root, subdirs, files in os.walk(path):
        if files == [] or files == ():
            continue

        csv_file = os.path.join(root, str(root.rsplit("\\", maxsplit = 1)[1]) + ".csv")
        
        df = pd.read_csv(csv_file, header=0).to_dict('records')
        new_df = []

        for rows in df:
            # if rows['label'] == "RBC" and (rows["area"] > 1500 or rows["area"] < 300):
            #     rows["label"] = ""
            #     os.remove(os.path.join(root, str(rows['id'] + '.png')))
            if pd.isna(rows['label']) or (rows['label'] == "RBC" and rows["area"] > 1500):
                rm_path = os.path.join(root, str(rows['id']) + '.png')
                if os.path.exists(rm_path):
                    os.remove(rm_path)
            else:    
                new_df.append(rows)


        print(csv_file)
        df = pd.DataFrame(new_df)
        df.to_csv(csv_file, index= False)

def create_cutouts_dataset(args):
    
    work_dir = args.work_dir
    orig_image_path = os.path.join(work_dir, args.grid_images_dir)
    input_dir = os.path.join(work_dir,args.output_dir)
    output_dir = os.path.join(work_dir, "compiled_dataset")
    dims = args.final_dimensions
    # i = 0
    if not os.path.exists(input_dir):
        raise("Enter a proper input directory containing the filtered masks (both rbc and wbc masks)")
    
    os.makedirs(output_dir, exist_ok=True)
    ids = []
    labels = []
    # go into each subdirectory masks generated by SAM
    for subroot, _, files in os.walk(input_dir):
        if files == () or files == []:
            continue
        
        # prepare appropriate paths
        folder_name = os.path.basename(subroot)
        orig_img = cv2.imread(os.path.join(orig_image_path, str(folder_name) + ".png"))
        csv_file = os.path.join(subroot, folder_name) + ".csv"
        
        df = pd.read_csv(csv_file, header = 0).to_records('dict')

        # go through each image and generated the cropped cut outs dataset for CNN training
        for rows in df:
            # if i == 2:
            #     break
            w = int(rows["bbox_w"])
            h = int(rows["bbox_h"])
            if w > dims or h > dims:
                continue
            
            x0 = int(rows["bbox_x0"])
            y0 = int(rows["bbox_y0"])
            
            # print(x0,y0,w,h)
            id = str(rows["id"])
            new_id = str(folder_name) + '_' + id + ".png"
            
            ids.append(new_id)
            labels.append(rows["label"])

            sub_img_path = os.path.join(subroot, id + ".png")
            bin_mask = cv2.imread(sub_img_path, 0)

            inter_mask = cv2.bitwise_and(orig_img, orig_img, mask=bin_mask)
            # plt.imshow(cv2.cvtColor(inter_mask, cv2.COLOR_BGR2RGB))
            # plt.show()
            inter_mask = inter_mask[y0:y0+h, x0:x0+w]
            # print(inter_mask.shape)
            # plt.imshow(cv2.cvtColor(inter_mask, cv2.COLOR_BGR2RGB))
            # plt.show()
            crop_h,crop_w = inter_mask.shape[:2]
            
            # print(crop_w, crop_h)
            pad_top = (dims - crop_h) // 2
            pad_bottom = dims - crop_h - pad_top
            pad_left = (dims - crop_w) // 2
            pad_right = dims - crop_w - pad_left

            # print(pad_top, pad_left, pad_left, pad_right)
            
            final_img = cv2.copyMakeBorder(inter_mask, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=[0,0,0])
            # plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB))
            # plt.show()

            final_img_path = os.path.join(output_dir, new_id)
            # print(final_img.shape)
            # print("")
            cv2.imwrite(final_img_path, final_img)
            
        # break

    compiled_csv_file = os.path.join(output_dir,"metadata.csv")
    metadata = dict()
    metadata["id"] = ids
    metadata["label"] = labels
    pd.DataFrame(metadata).to_csv(compiled_csv_file, index = False)
    
    return

def data_split(args):
    work_dir = os.path.join(args.work_dir, "compiled_dataset")
    train_wbc_dir = os.path.join(work_dir, r"train\WBC")
    os.makedirs(train_wbc_dir, exist_ok=True)
    val_wbc_dir = os.path.join(work_dir, r"val\WBC")
    os.makedirs(val_wbc_dir, exist_ok=True)
    test_wbc_dir = os.path.join(work_dir, r"test\WBC")
    os.makedirs(test_wbc_dir, exist_ok=True)

    train_rbc_dir = os.path.join(work_dir, r"train\RBC")
    os.makedirs(train_rbc_dir, exist_ok=True)
    val_rbc_dir = os.path.join(work_dir, r"val\RBC")
    os.makedirs(val_rbc_dir, exist_ok=True)
    test_rbc_dir = os.path.join(work_dir, r"test\RBC")
    os.makedirs(test_rbc_dir, exist_ok=True)
    
    metadata = os.path.join(work_dir, "metadata.csv")
    print(metadata)
    df = pd.read_csv(metadata, header = 0).reset_index(drop=True)
    #rbc, wbc = df.groupby("label")
    #rbc, wbc = rbc[1], wbc[1]

    #new_df = pd.concat([rbc, wbc], axis = 0).sample(frac=1)
    #df = df.sample(frac=1, random_state=6500).reset_index(drop=True)
    label = df["label"]

    df_train, df_temp =  train_test_split(df, random_state=6500, test_size=0.25, stratify=label)
    label = df_temp["label"]
    print(df_temp)
    df_val, df_test = train_test_split(df_temp, random_state=6500, test_size=0.4, stratify=label)
    
    for rows in df_train.to_dict('records'):
        id = rows["id"]
        if rows["label"] == "RBC":
            shutil.copyfile(os.path.join(work_dir, id), os.path.join(train_rbc_dir, id))
        else:
            shutil.copyfile(os.path.join(work_dir, id), os.path.join(train_wbc_dir, id))
    
    for rows in df_val.to_dict('records'):
        id = rows["id"]
        if rows["label"] == "RBC":
            shutil.copyfile(os.path.join(work_dir, id), os.path.join(val_rbc_dir, id))
        else:
            shutil.copyfile(os.path.join(work_dir, id), os.path.join(val_wbc_dir, id))
    
    for rows in df_test.to_dict('records'):
        id = rows["id"]
        if rows["label"] == "RBC":
            shutil.copyfile(os.path.join(work_dir, id), os.path.join(test_rbc_dir,id))
        else:
            shutil.copyfile(os.path.join(work_dir, id), os.path.join(test_wbc_dir, id))

    return 

def wbc_train_data_augmenter(path):
    if not os.path.exists(path) or os.listdir(path) == []:
        raise("Ensure proper path with required images is passed onto this function")
    
    data_augmentation = image.ImageDataGenerator(horizontal_flip = True,
                                                 vertical_flip = True,
                                                 rotation_range = 90)
    
    img_list = os.listdir(path)
    for imag in img_list:
        if imag.endswith(".png"):
            i = 0
            img = image.load_img(os.path.join(path, imag))
            img_array = image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)

            for batch in data_augmentation.flow(img_array, batch_size=1, save_to_dir=path, save_prefix='aug-'+str(i), save_format='png'):
                i += 1
                if i == 9:
                    break
    
    return
            




    
if __name__ == "__main__":
    args = parser.parse_args()
    #copy_wbc_folders_first(args)
    #create_simple_cutout()
    #csv_labeller(r"D:\UCC\Thesis\segment-anything-main\assets\Mask_sub_folders")
    #edit_csv(r"D:\UCC\Thesis\segment-anything-main\assets\rbc-wbc_image_masks")
    #create_cutouts_dataset(args)
    #print("printing excess")
    data_split(args)
    wbc_train_data_augmenter(os.path.join(args.work_dir, r"compiled_dataset\train\WBC"))
    

